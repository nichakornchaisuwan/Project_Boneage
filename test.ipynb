{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMqrL+hcH2SdyQVOubzdCp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nichakornchaisuwan/Project_Boneage/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard lib imports\n",
        "import os\n",
        "import csv\n",
        "import glob\n",
        "import time\n",
        "import argparse\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import os.path as osp"
      ],
      "metadata": {
        "id": "te6DLf6PTS45"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install horovod"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQu7E6huTYyo",
        "outputId": "7a9721fd-50cc-4953-9c9a-143273e90fc9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting horovod\n",
            "  Downloading horovod-0.26.1.tar.gz (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 31.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from horovod) (1.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from horovod) (5.4.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from horovod) (6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from horovod) (21.3)\n",
            "Requirement already satisfied: cffi>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from horovod) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.4.0->horovod) (2.21)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->horovod) (3.0.9)\n",
            "Building wheels for collected packages: horovod\n",
            "  Building wheel for horovod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for horovod: filename=horovod-0.26.1-cp38-cp38-linux_x86_64.whl size=28370004 sha256=da308faa3f3a1d0ff328f4ca9d804ed733d38342cd07b56ded40030c2765aedd\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/0b/90/d53058f75f3ae3db9557f3e55dd8c016b2397e9b38557c8b66\n",
            "Successfully built horovod\n",
            "Installing collected packages: horovod\n",
            "Successfully installed horovod-0.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import horovod.torch as hvd\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.distributed import DistributedSampler"
      ],
      "metadata": {
        "id": "-737KhuKTTd6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/BCV-Uniandes/Bonet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8voRfW-TYijs",
        "outputId": "adfce087-2b9f-40bf-aad7-01251cbbcc8e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Bonet'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Total 52 (delta 0), reused 0 (delta 0), pack-reused 52\u001b[K\n",
            "Unpacking objects: 100% (52/52), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd Bonet"
      ],
      "metadata": {
        "id": "i3pABpQbYwyT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Local imports\n",
        "import Bonet\n",
        "from Bonet.models.bonet import BoNet"
      ],
      "metadata": {
        "id": "k7k7CioFeSX0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from Bonet.data.data_loader import BoneageDataset ###########"
      ],
      "metadata": {
        "id": "vlCTH_47g9rH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Bonet.data.__pycache__.boneage_loader import BoneageDataset  ############"
      ],
      "metadata": {
        "id": "XdlwEDGBkWRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Other imports\n",
        "from tqdm import tqdm\n",
        "import pdb"
      ],
      "metadata": {
        "id": "o1iNJikeYgdb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "_Lt_icbZe2r3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()"
      ],
      "metadata": {
        "id": "0tNOxrPxe2ob"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloading-related settings\n",
        "parser.add_argument('--heatmaps', default=False, action='store_true',\n",
        "                help='Test model with gaussian heatmaps')\n",
        "parser.add_argument('--cropped', default=False, action='store_true',\n",
        "                help='Test model with cropped images according to bbox')\n",
        "parser.add_argument('--dataset', default='RSNA', type=str,choices=['RSNA','RHPE'],\n",
        "                help='Dataset to perform test')"
      ],
      "metadata": {
        "id": "tJGu09CPe2lv",
        "outputId": "6045aea1-b488-4d5b-d26f-b930089b418f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--dataset'], dest='dataset', nargs=None, const=None, default='RSNA', type=<class 'str'>, choices=['RSNA', 'RHPE'], help='Dataset to perform test', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloading-related settings\n",
        "parser.add_argument('--data-test', default='data/test/', type=str,\n",
        "                help='path to test data folder')\n",
        "parser.add_argument('--ann-path-test', default='test.csv', type=str,\n",
        "                help='path to BAA annotations file')\n",
        "parser.add_argument('--rois-path-test', default='test.json',\n",
        "                type=str, help='path to ROIs annotations in coco format')\n",
        "\n",
        "parser.add_argument('--save-folder', default='TRAIN/new_test/',\n",
        "                help='location to save checkpoint models')\n",
        "parser.add_argument('--snapshot', default='boneage_bonet_weights.pth',\n",
        "                help='path to weight snapshot file')\n",
        "\n",
        "\n",
        "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
        "                help='number of data loading workers (default: 4)')"
      ],
      "metadata": {
        "id": "_efsE5sFe2i2",
        "outputId": "2440a199-4ebb-403c-fe15-7324f1458497",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['-j', '--workers'], dest='workers', nargs=None, const=None, default=4, type=<class 'int'>, choices=None, help='number of data loading workers (default: 4)', metavar='N')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training procedure settings\n",
        "parser.add_argument('--batch-size', default=1, type=int,\n",
        "                help='Batch size for training')\n",
        "\n",
        "parser.add_argument('--seed', type=int, default=1111,\n",
        "                    help='random seed')\n",
        "parser.add_argument('--gpu', type=str, default='2,3')\n",
        "\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "args_dict = vars(args)\n",
        "print('Argument list to program')\n",
        "print('\\n'.join(['--{0} {1}'.format(arg, args_dict[arg])\n",
        "                 for arg in args_dict]))\n",
        "print('\\n\\n')\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
        "\n",
        "if not os.path.exists(os.path.join(args.save_folder, 'inference')):\n",
        "    os.makedirs(os.path.join(args.save_folder, 'inference'))"
      ],
      "metadata": {
        "id": "nZa_1c-we2gM",
        "outputId": "786e7c22-b30d-4f32-8f70-576a9916aa2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-77d54680dad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training procedure settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m parser.add_argument('--batch-size', default=1, type=int,\n\u001b[0m\u001b[1;32m      3\u001b[0m                 help='Batch size for training')\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m parser.add_argument('--seed', type=int, default=1111,\n",
            "\u001b[0;32m/usr/lib/python3.8/argparse.py\u001b[0m in \u001b[0;36madd_argument\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1396\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"length of metavar tuple does not match nargs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1398\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_argument_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1759\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption_strings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1761\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optionals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1762\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_positionals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1602\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ArgumentGroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1603\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m         \u001b[0;31m# resolve any conflicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_conflict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0;31m# add to actions list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/argparse.py\u001b[0m in \u001b[0;36m_check_conflict\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1549\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfl_optionals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mconflict_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m             \u001b[0mconflict_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfl_optionals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_conflict_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconflicting_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/argparse.py\u001b[0m in \u001b[0;36m_handle_conflict_error\u001b[0;34m(self, action, conflicting_actions)\u001b[0m\n\u001b[1;32m   1558\u001b[0m                                      \u001b[0;32mfor\u001b[0m \u001b[0moption_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m                                      in conflicting_actions])\n\u001b[0;32m-> 1560\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mconflict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_conflict_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconflicting_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mArgumentError\u001b[0m: argument --batch-size: conflicting option string: --batch-size"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Horovod settings\n",
        "hvd.init()\n",
        "torch.cuda.set_device(hvd.local_rank())\n",
        "torch.cuda.manual_seed(hvd.size())\n",
        "\n",
        "args.distributed = hvd.size() > 1\n",
        "args.rank = hvd.rank()\n",
        "args.size = hvd.size()"
      ],
      "metadata": {
        "id": "QIBtJGe2fBuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE THE NETWORK ARCHITECTURE AND LOAD THE BEST MODEL\n",
        "if args.heatmaps:\n",
        "    from models.bonet_heatmap import BoNet\n",
        "else:\n",
        "    from models.bonet import BoNet\n",
        "\n",
        "net = BoNet()\n",
        "\n",
        "if args.rank == 0:\n",
        "    print('---> Number of params: {}'.format(\n",
        "        sum([p.data.nelement() for p in net.parameters()])))\n",
        "\n",
        "if osp.exists(args.snapshot):\n",
        "    model_to_load=args.snapshot\n",
        "else:\n",
        "    model_to_load=args.save_folder+'/'+args.snapshot\n",
        "\n",
        "if osp.exists(model_to_load) and args.rank == 0:\n",
        "    print('Loading state dict from: {0}'.format(model_to_load))\n",
        "    snapshot_dict = torch.load(model_to_load, map_location=lambda storage, loc: storage)\n",
        "    weights= net.state_dict()\n",
        "    new_snapshot_dict=snapshot_dict.copy()\n",
        "    for key in snapshot_dict:\n",
        "        if key not in weights.keys():\n",
        "            new_key='inception_v3.'+key\n",
        "            new_snapshot_dict[new_key]=snapshot_dict[key]\n",
        "            new_snapshot_dict.pop(key)\n",
        "\n",
        "    net.load_state_dict(new_snapshot_dict)\n",
        "\n",
        "net = net.to(device)"
      ],
      "metadata": {
        "id": "iqNMXFR9fBi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criterion\n",
        "criterion = nn.L1Loss()"
      ],
      "metadata": {
        "id": "DhMbFScSfBfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Horovod\n",
        "hvd.broadcast_parameters(net.state_dict(), root_rank=0)"
      ],
      "metadata": {
        "id": "D0pHfNR1e2dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "test_transform = transforms.Compose([transforms.Resize((500, 500)),\n",
        "                               transforms.ToTensor()])\n",
        "\n",
        "if args.heatmaps:\n",
        "    from data.data_loader import Boneage_HeatmapDataset as Dataset\n",
        "else:\n",
        "    from data.data_loader import BoneageDataset as Dataset\n",
        "\n",
        "test_dataset = Dataset(args.data_test, args.ann_path_test,args.rois_path_test,\n",
        "                                  img_transform=test_transform,crop=args.cropped,dataset=args.dataset)"
      ],
      "metadata": {
        "id": "Hi2F48K1fRYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data samplers\n",
        "test_sampler = None\n",
        "\n",
        "if args.distributed:\n",
        "    test_sampler = DistributedSampler(test_dataset,\n",
        "                                      num_replicas=args.size,\n",
        "                                      rank=args.rank)\n",
        "\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                        shuffle=False, \n",
        "                        sampler=test_sampler,\n",
        "                        batch_size=1,\n",
        "                        num_workers=args.workers)\n",
        "\n",
        "def main():\n",
        "    print('Inference begins...')\n",
        "    carpograms = pd.read_csv(os.path.join('Paths', args.ann_path_test))\n",
        "    ids = carpograms.ix[:, 0]\n",
        "    p_dict = dict.fromkeys(ids)\n",
        "    p_dict = test(args, net, test_loader, test_sampler,\n",
        "                  criterion, p_dict)\n",
        "    df = pd.DataFrame.from_dict(p_dict, orient=\"index\")\n",
        "    df.to_csv(os.path.join(args.save_folder, 'test.csv'))\n",
        "\n",
        "\n",
        "\n",
        "def evaluate():\n",
        "    net.eval()\n",
        "    epoch_total_loss = AverageMeter()\n",
        "    for (batch_idx, (imgs, bone_ages, genders, _)) in enumerate(test_loader):\n",
        "        imgs = imgs.to(device)\n",
        "        bone_ages = bone_ages.to(device)\n",
        "        genders = genders.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = net(imgs, genders)\n",
        "        loss = criterion(outputs.squeeze(), bone_ages)\n",
        "        loss = metric_average(loss.item(), 'loss')\n",
        "        epoch_total_loss.update(loss, 1)\n",
        "\n",
        "    epoch_total_loss = epoch_total_loss.avg\n",
        "\n",
        "    if args.rank == 0:\n",
        "        print('Val loss: {:.5f}'.format(epoch_total_loss))\n",
        "\n",
        "    return epoch_total_loss\n",
        "\n",
        "def test(args, net, loader, sampler, criterion, p_dict):\n",
        "    net.eval()\n",
        "    epoch_loss = AverageMeter()\n",
        "    with torch.no_grad():\n",
        "        for i, batch in tqdm(enumerate(test_loader, 0)):\n",
        "            inputs, labels, gender, p_id = batch\n",
        "            inputs, gender = Variable(inputs).cuda(), Variable(gender).cuda()\n",
        "            labels = Variable(labels).cuda()\n",
        "            outputs = net(inputs, gender)\n",
        "\n",
        "            p_dict[p_id] = outputs\n",
        "            loss = criterion(outputs.squeeze_(), labels)\n",
        "            \n",
        "            epoch_loss.update(loss)\n",
        "    loss = metric_average(epoch_loss.avg,'loss')\n",
        "\n",
        "    if args.rank == 0:\n",
        "        print('Test loss: {}'.format(loss))\n",
        "    return p_dict\n",
        "\n",
        "\n",
        "def metric_average(val, name):\n",
        "    tensor = torch.tensor(val)\n",
        "    avg_tensor = hvd.allreduce(tensor, name=name)\n",
        "    return avg_tensor.item()\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "zmxh8x9IfRU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XLQQiB0CfRSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wk-dC8NUfRQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AUfGjIxZfRNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5efChFk4fRKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4sbbVY5SfRHr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}